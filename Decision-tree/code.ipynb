{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decision_tree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-YK9zOLoZMw",
        "outputId": "d8c8b6db-eb8e-4b96-9774-d25f7e439007"
      },
      "source": [
        "!apt install graphviz graphviz-dev\n",
        "!pip install wget\n",
        "!pip install pygraphviz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'libgraphviz-dev' instead of 'graphviz-dev'\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
            "  libgvc6-plugins-gtk libxdot4\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libgvc6-plugins-gtk libxdot4\n",
            "0 upgraded, 8 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 2,120 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libxdot4 amd64 2.40.1-2 [15.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6-plugins-gtk amd64 2.40.1-2 [18.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgraphviz-dev amd64 2.40.1-2 [57.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Fetched 2,120 kB in 1s (1,868 kB/s)\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../1-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../2-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../3-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libxdot4.\n",
            "Preparing to unpack .../4-libxdot4_2.40.1-2_amd64.deb ...\n",
            "Unpacking libxdot4 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvc6-plugins-gtk.\n",
            "Preparing to unpack .../5-libgvc6-plugins-gtk_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvc6-plugins-gtk (2.40.1-2) ...\n",
            "Selecting previously unselected package libgraphviz-dev.\n",
            "Preparing to unpack .../6-libgraphviz-dev_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgraphviz-dev (2.40.1-2) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../7-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libxdot4 (2.40.1-2) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgvc6-plugins-gtk (2.40.1-2) ...\n",
            "Setting up libgraphviz-dev (2.40.1-2) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=70737d1d99a1beb4becd8c2ee3541643fff61a584ca96b8e6716226dbbf4cd9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting pygraphviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/d6/2c56f09ee83dbebb62c40487e4c972135661b9984fec9b30b77fb497090c/pygraphviz-1.7.zip (118kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 5.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygraphviz: filename=pygraphviz-1.7-cp37-cp37m-linux_x86_64.whl size=166131 sha256=3e84bffa93a6d9c4a6865611edd9cf968601b9ab950facd2522ac6615725ffee\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/59/00/14934a4292c4359eeabcdbf90f33d309b55d0f1be8a1262523\n",
            "Successfully built pygraphviz\n",
            "Installing collected packages: pygraphviz\n",
            "Successfully installed pygraphviz-1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m48p7tyoQN9"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "def download(target_name = 'iris.data'):\n",
        "    \"\"\"\n",
        "    Download the mushroom dataset from UCI\n",
        "    :param target_name: target path name\n",
        "    \"\"\"\n",
        "    if not os.path.exists(target_name):\n",
        "        url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "        wget.download(url, target_name)\n",
        "\n",
        "download()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjuFdo49a_qc"
      },
      "source": [
        "# Core Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7fVwr2shOAF"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, recall_score\n",
        "import pygraphviz as pgv\n",
        "\n",
        "\n",
        "class C45Classifier(object):\n",
        "\n",
        "    def entropy(self,dataset,fea=-1):\n",
        "        labels = dataset[:,fea]\n",
        "        h = 0.0\n",
        "        for k,v in zip(*np.unique(labels,return_counts=True)):\n",
        "            h -= v / labels.shape[0] * np.log2([v / labels.shape[0]])[0]\n",
        "        return h\n",
        "\n",
        "    def bin_split_data(self,dataset,index,value):\n",
        "        smaller = dataset[dataset[:,index]<=value]\n",
        "        bigger = dataset[dataset[:,index]>value]\n",
        "        return smaller, bigger\n",
        "\n",
        "    def reg_loss(self,dataset):\n",
        "        a = np.mean(dataset[:,-1])\n",
        "        return np.square(dataset[:,-1]-a).sum()\n",
        "\n",
        "    def info_gain(self, dataset, feature, val=None):\n",
        "        if val == None:\n",
        "            feature_values = np.unique(dataset[:,feature])\n",
        "            entropy_sub_dataset = 0.0\n",
        "            for val in feature_values:\n",
        "                sub_dataset = dataset[dataset[:,feature]==val]\n",
        "                entropy_sub_dataset += sub_dataset.shape[0]/dataset.shape[0] * self.entropy(sub_dataset)\n",
        "            return self.entropy(dataset) - entropy_sub_dataset\n",
        "        else:\n",
        "            sm, bg = self.bin_split_data(dataset,feature,val)\n",
        "            hda =- sm.shape[0]/dataset.shape[0]*self.entropy(sm) - bg.shape[0]/dataset.shape[0]*self.entropy(bg)\n",
        "            hd = self.entropy(dataset)\n",
        "            return hd-hda\n",
        "\n",
        "    def info_gain_ratio(self, dataset, feature, val=None):\n",
        "        if val == None:\n",
        "            feature_values = np.unique(dataset[:,feature])\n",
        "            entropy_sub_dataset = 0.0\n",
        "            for val in feature_values:\n",
        "                sub_dataset=dataset[dataset[:,feature]==val]\n",
        "                entropy_sub_dataset += sub_dataset.shape[0]/dataset.shape[0] * self.entropy(sub_dataset)\n",
        "            Had = self.entropy(dataset,feature)\n",
        "            return (self.entropy(dataset) - entropy_sub_dataset)/Had\n",
        "        else:\n",
        "            sm, bg=self.bin_split_data(dataset,feature,val)\n",
        "            hda =- sm.shape[0]/dataset.shape[0]*self.entropy(sm) - bg.shape[0]/dataset.shape[0]*self.entropy(bg)\n",
        "            hd = self.entropy(dataset)\n",
        "            had =- np.log2(sm.shape[0]/dataset.shape[0]) - np.log2(bg.shape[0]/dataset.shape[0])\n",
        "            return (hd-hda)/had\n",
        "\n",
        "    def select_feature(self, dataset, features1, features2):\n",
        "        if dataset.shape[0]<=1*2:\n",
        "            return None, self.majority_label(dataset[:,-1])\n",
        "\n",
        "        if len(features1)!=0:\n",
        "            info_gains = [(self.info_gain_ratio(dataset, x), x) for x in features1]\n",
        "            loss = max(info_gains,key=lambda x:x[0])[0]\n",
        "            best_index = max(info_gains,key=lambda x:x[0])[1]\n",
        "        else:\n",
        "            loss, best_index= -np.inf, 0\n",
        "        best_split, uncon, c = 0, True, 0\n",
        "  \n",
        "        for i in features2:\n",
        "            undata = np.unique(dataset[:,i])\n",
        "            if undata.shape[0]==1:\n",
        "                c += 1\n",
        "            for val in undata:\n",
        "                sm, bg = self.bin_split_data(dataset, i, val)\n",
        "                if sm.shape[0]<1 or bg.shape[0]<1:\n",
        "                    continue\n",
        "                loss1 = self.info_gain_ratio(dataset,i,val)\n",
        "                if loss<loss1:\n",
        "                    loss, best_index, best_split, uncon = loss1, i, val, False\n",
        "        if c == dataset.shape[1]-1:\n",
        "            return None, self.majority_label(dataset[:,-1])\n",
        "        if uncon:\n",
        "            return max(info_gains)[1], None\n",
        "        return best_index, best_split\n",
        "     \n",
        "    def majority_label(self, labels):\n",
        "        return max(zip(*np.unique(labels,return_counts=True)),key=lambda x:x[1])[0]\n",
        "\n",
        "    def build_tree(self, dataset, features1, features2):\n",
        "        labels = dataset[:,-1]\n",
        "        features = features1+features2\n",
        "        if np.unique(labels).shape[0] == 1:\n",
        "            return {'label': labels[0]}\n",
        "        if len(features) == 0:\n",
        "            return {'label': self.majority_label(labels)}\n",
        "        best_feature, best_split = self.select_feature(dataset, features1, features2)\n",
        "        if best_split == None:\n",
        "            tree = {'feature': best_feature, 'children': {}}\n",
        "            best_feature_values = np.unique(dataset[:, best_feature])\n",
        "            for val in best_feature_values:\n",
        "                sub_dataset = dataset[dataset[:, best_feature]==val]\n",
        "                if len(sub_dataset) == 0:\n",
        "                    tree['children'][val] = {\n",
        "                        'label': self.majority_label(labels)}\n",
        "                else:\n",
        "                    tree['children'][val] = self.build_tree(\n",
        "                        sub_dataset, [x for x in features1 if x != best_feature],features2)\n",
        "        else:\n",
        "            if best_feature == None:\n",
        "                return {'label': best_split}\n",
        "            tree = {'feature': best_feature, 'children': {},'best_split':best_split}\n",
        "            sm, bg = self.bin_split_data(dataset, best_feature, best_split)\n",
        "            tree['children']['left'] = self.build_tree(sm, features1, [x for x in features2 if x != best_feature])\n",
        "            tree['children']['right'] = self.build_tree(bg, features1, [x for x in features2 if x != best_feature])\n",
        "        return tree\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        dataset = np.c_[X,y]\n",
        "        feature1, feature2 = [], []\n",
        " \n",
        "        for i in range(dataset.shape[1]-1):\n",
        "            if np.unique(dataset[:,i]).shape[0]<=10:\n",
        "                feature1.append(i)\n",
        "            else:\n",
        "                feature2.append(i)\n",
        "        self.tree = self.build_tree(dataset, feature1, feature2)\n",
        "\n",
        "    def _predict(self, tree, x):\n",
        "        if 'feature' in tree:\n",
        "            if 'best_split' in tree:\n",
        "                if x[tree['feature']]<=tree['best_split']:\n",
        "                    return self._predict(tree['children']['left'], x)\n",
        "                else:\n",
        "                    return self._predict(tree['children']['right'], x)\n",
        "            else:\n",
        "                return self._predict(tree['children'][x[tree['feature']]], x)\n",
        "        else:\n",
        "            return tree['label']\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.apply_along_axis(lambda x:self._predict(self.tree, x),1, X)\n",
        "\n",
        "    def draw_tree(self, k):\n",
        "        tr = pgv.AGraph()\n",
        "        label_names = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]\n",
        "        num = [0]\n",
        "        def DFS(rt):\n",
        "            if rt.get('children') != None:\n",
        "                now = f\"feature={rt['feature']}\\nbest_split={rt['best_split']}\"\n",
        "                if rt['children'].get('left') != None:\n",
        "                    ch = rt['children']['left']\n",
        "                    Next = \"\"\n",
        "                    if ch.get('feature') != None:\n",
        "                        Next = f\"feature={ch['feature']}\\nbest_split={ch['best_split']}\"\n",
        "                    elif ch.get('label') != None:\n",
        "                        tr.add_node(num[0], label=f\"{label_names[int(ch['label'])]}\")\n",
        "                        Next = tr.get_node(num[0])\n",
        "                        num[0] += 1\n",
        "                  \n",
        "                    tr.add_edge(now, Next)\n",
        "                    DFS(ch)\n",
        "                if rt['children'].get('right') != None:\n",
        "                    ch = rt['children']['right']\n",
        "                    Next = \"\"\n",
        "                    if ch.get('feature') != None:\n",
        "                        Next = f\"feature={ch['feature']}\\nbest_split={ch['best_split']}\"\n",
        "                    elif ch.get('label') != None:\n",
        "                        tr.add_node(num[0], label=f\"{label_names[int(ch['label'])]}\")\n",
        "                        Next = tr.get_node(num[0])\n",
        "                        num[0] += 1\n",
        "        \n",
        "                    tr.add_edge(now, Next)\n",
        "                    DFS(ch)\n",
        "        DFS(self.tree)\n",
        "        tr.layout(\"dot\")\n",
        "        tr.draw(f\"file_{k}.png\")\n",
        "        \n",
        "    def score(self, X, y, k):\n",
        "         y_pred = self.predict(X)\n",
        "         print(f'Accuracy = {accuracy_score(y, y_pred)}')\n",
        "         print(f'Confusion Matrix= {confusion_matrix(y, y_pred)}')\n",
        "         print(f\"F1 Score = {f1_score(y, y_pred, average='weighted')}\")\n",
        "         print(f\"Recall Score = {recall_score(y, y_pred, average='weighted')}\")\n",
        "         self.draw_tree(k)\n",
        "    \n",
        "         \n",
        "         "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdxAHCV5bEo7"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn6rqJxoSkaV"
      },
      "source": [
        "dataset_path = 'iris.data'\n",
        "X = np.delete(np.genfromtxt(dataset_path, delimiter=\",\"), 4, 1)\n",
        "\n",
        "y = []\n",
        "label_dict = {\n",
        "    \"Iris-setosa\": 0,\n",
        "    \"Iris-versicolor\": 1,\n",
        "    \"Iris-virginica\": 2\n",
        "}\n",
        "with open(dataset_path) as file:\n",
        "    lines = file.read().splitlines()\n",
        "    for line in lines:\n",
        "        if not line == \"\": \n",
        "            y.append(label_dict[line.split(\",\")[-1]])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrS5ZvO8bHNp"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnbV8IYD_ELd",
        "outputId": "8fd46e02-cd96-4b5d-d537-74c201c38e83"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "DecisionTree = C45Classifier()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "DecisionTree.fit(X_train, y_train)\n",
        "DecisionTree.score(X_test, y_test, 0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9111111111111111\n",
            "Confusion Matrix= [[14  2  0]\n",
            " [ 1 17  0]\n",
            " [ 0  1 10]]\n",
            "F1 Score = 0.9118459230513559\n",
            "Recall Score = 0.9111111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OfXY0a575eV",
        "outputId": "07b8e746-c1d1-491d-a93d-beb58298d84f"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "i = 1\n",
        "kf = KFold(n_splits=4, random_state=0, shuffle=True)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = np.array(y)[train_index], np.array(y)[test_index]\n",
        "    DecisionTree = C45Classifier()\n",
        "    DecisionTree.fit(X_train, y_train)\n",
        "    DecisionTree.score(X_test, y_test, i)\n",
        "    i+=1\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.8157894736842105\n",
            "Confusion Matrix= [[11  2  0]\n",
            " [ 1 11  4]\n",
            " [ 0  0  9]]\n",
            "F1 Score = 0.8142517736347137\n",
            "Recall Score = 0.8157894736842105\n",
            "Accuracy = 0.8421052631578947\n",
            "Confusion Matrix= [[ 9  0  0]\n",
            " [ 3  8  3]\n",
            " [ 0  0 15]]\n",
            "F1 Score = 0.8298017771701982\n",
            "Recall Score = 0.8421052631578947\n",
            "Accuracy = 0.918918918918919\n",
            "Confusion Matrix= [[15  1  0]\n",
            " [ 0  5  2]\n",
            " [ 0  0 14]]\n",
            "F1 Score = 0.9171662978114591\n",
            "Recall Score = 0.918918918918919\n",
            "Accuracy = 0.8108108108108109\n",
            "Confusion Matrix= [[12  0  0]\n",
            " [ 3 10  0]\n",
            " [ 2  2  8]]\n",
            "F1 Score = 0.8089468779123952\n",
            "Recall Score = 0.8108108108108109\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}